{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c81d538",
   "metadata": {},
   "source": [
    "![MIoT_GDPI](img/MIOT_GDPI_header.png)\n",
    "\n",
    "# Unidad 01 - Introducción al stream learning\n",
    "\n",
    "El objetivo principal de esta práctica es que os familiaricéis con los conceptos más básicos del Aprendizaje *Online* (aka *stream learning* o *incremental learning*). Se desarrollarán brevemente algunas definiciones para entender el contexto, la problemática y las diferencias con el aprendizaje automático tradicional y se introducirá en el uso de la librería [River](https://riverml.xyz/) que permite desarrollar modelos incrementales de forma intuitiva empleando Python.  \n",
    "\n",
    "\n",
    "La mayor parte del contenido de este Notebook se dedica a explicar los aspectos fundamentales del aprendizaje incremental, apoyándose en ejemplos concretos que ilustran su aplicación a un problema real. Es crucial que dediquéis tiempo a leer y comprender el material, en lugar de simplemente ejecutar el código. Os invitamos a experimentar modificando y variando el código proporcionado para que podáis explorar las distintas opciones y profundizar en su funcionamiento.\n",
    "\n",
    "\n",
    "\n",
    "**Importante**: El Notebook contiene varios ejercicios sencillos. Deberéis desarrollarlos durante la clase y enviarlos por el aula virtual del curso, en la tarea correspondiente.\n",
    "\n",
    "\n",
    "\n",
    "## Referencias útiles para la práctica\n",
    "1. API Pandas: [https://pandas.pydata.org/docs/reference/index.html](https://pandas.pydata.org/docs/reference/index.html)\n",
    "2. Api River: [https://riverml.xyz](https://riverml.xyz)\n",
    "3. Api Scikit-Learn: [https://scikit-learn.org/stable/api/index.html](https://scikit-learn.org/stable/api/index.html)\n",
    "4. Bahri, M., Bifet, A., Gama, J., Gomes, H. M., & Maniu, S. (2021). [Data stream analysis: Foundations, major tasks and tools](https://doi.org/10.1002/widm.1405). Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 11(3), e1405.\n",
    "5. Gomes, H. M., Read, J., Bifet, A., Barddal, J. P., & Gama, J. (2019). [Machine learning for streaming data: state of the art, challenges, and opportunities](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://kdd.org/exploration_files/3._CR_7._Machine_learning_for_streaming_data_state_of_the_art-Final.pdf). ACM SIGKDD Explorations Newsletter, 21(2), 6-22.\n",
    "\n",
    "## 1. Introducción al concepto de Stream Learning\n",
    "\n",
    "El tiempo es una característica clave de la mayoría de las actividades humanas de interés.  Ya sea la evolución temporal del mercado de valores, la dinámica de las redes sociales, la entrada sensorial a los robots o en la fabricación dentro de las líneas de producción industriales, el flujo del tiempo es un factor importante para la comprensión del sistema y la toma de decisiones. \n",
    "\n",
    "A través del paso del tiempo, la información se actualiza y evoluciona y, ante estos cambios, nos adaptamos a la nueva información, interpretamos su significado y modificamos, si es necesario, nuestras suposiciones subyacentes. Por lo tanto, los sistemas de IA/ML en tiempo real deben ser capaces de adaptarse de manera similar para ser efectivos.\n",
    "\n",
    "Los datos continuos basados en el tiempo se consideran *streams* (flujos). Los algoritmos de aprendizaje de IA que pueden adaptarse a estos flujos de manera \"incremental\" han dado lugar a un nuevo paradigma, conocido como *stream learning*, *incremental learning* u *online learning*. \n",
    "\n",
    "Debido a que los sistemas reales están caracterizados por fenómenos que pueden ocurrir en diferentes escalas temporales (a corto o a largo plazo), estos sistemas IA pueden analizar información también en múltiples escalas. Por ejemplo, el comportamiento a corto plazo podría ser las fluctuaciones de \n",
    "humedad en el desarrollo de un producto concreto en una línea industrial a lo largo de un día, mientras que el comportamiento a largo plazo podría considerarse el promedio de humedades a lo largo de un año en el que la influencia de las estaciones meteorológicas es relevante para la producción.\n",
    "\n",
    "¿Cómo podría un sistema de IA proporcionar predicciones precisas teniendo en cuenta escalas de tiempo radicalmente diferentes? Más importante aún, ¿Cómo podría un sistema de IA comprender que el flujo de datos entrante está evolucionando continuamente y que los fenómenos subyacentes pueden deberse a nuevas tendencias que no estaban presentes en los datos de entrenamiento originales? Estas son precisamente las preguntas que abordan los sistemas de aprendizaje incremental (aka *online learning* o *stream learning*).\n",
    "\n",
    "###  1.1. Comparativa con el ML clásico\n",
    "\n",
    "Para comprender mejor el aprendizaje *online*, es útil compararlo con el enfoque tradicional de aprendizaje automático (*offline learning* o *batch learning*). Como ejemplo, consideremos una señal con dependencias temporales como la de un sensor de temperatura, que consta de dos elementos: el tiempo y la amplitud correspondiente (un voltaje escalado, correlacionado con la temperatura).\n",
    "\n",
    "Un algoritmo clásico de aprendizaje automático podría obtener información en múltiples escalas temporales analizando primero la relación a corto plazo de la señal; esto se lograría mediante el uso de una ventana deslizante y analizando las características de la señal dentro de cada una de esas ventanas. Con ventanas más grandes y datos históricos, el algoritmo clásico podría estudiar estructuras temporales más largas.\n",
    "\n",
    "De esta manera, un enfoque tradicional de aprendizaje automático generalmente construiría un conjunto de datos para entrenamiento y evaluación. Este conjunto de datos incluiría varias secciones de la señal que corresponden a características y salidas en diferentes escalas temporales, proporcionando cierto grado de predictibilidad tanto para eventos futuros a corto como a largo plazo. Sin embargo, las limitaciones de este enfoque se hacen evidentes de inmediato. En primer lugar, las predicciones se vuelven más complejas porque el sistema debe distinguir entre las diferentes escalas temporales (y los límites entre ellas). Si el sistema debe hacer una predicción basada en un solo punto de datos de entrada, ¿cómo se incorpora la información multiescala en el algoritmo de predicción? En otras palabras, la evolución a largo plazo de la entrada no es evidente en un solo punto de datos, lo que dificulta capturar predicciones a largo plazo sobre cambios subyacentes.\n",
    "\n",
    "Como resultado, los enfoques clásicos de aprendizaje automático para la predicción multitemporal suelen ser *ad-hoc* y dependen de modelos diseñados específicamente para adaptarse a la evolución de los fenómenos subyacentes, lo que hace que el entrenamiento previo sea incompleto o inexacto. Por lo tanto, el enfoque común para abordar este problema es reentrenar y volver a desplegar el modelo de aprendizaje automático de manera periódica. En algunos sistemas, estas actualizaciones del modelo se realizan en escalas de tiempo cortas, como minutos o incluso segundos.\n",
    "\n",
    "### 1.2. El nuevo paradigma: \n",
    "\n",
    "Para abordar de manera efectiva los flujos temporales y los problemas  descritos anteriormente, surge el aprendizaje incremental (aka *online learning o *stream learning*), es decir, sistemas ML específicamente diseñados para manejar flujos (*streams*) de datos continuos y, a menudo, infinitos. Con cada nueva observación que estos sistemas reciben ajustan el modelo de predicción, en lugar de utilizar conjuntos de datos estáticos (ej. datasets de entrenamiento) o grandes lotes (*batches*).\n",
    "\n",
    "Si bien la diferencia entre el aprendizaje *online* y el aprendizaje clásico puede parecer sutil, existen varias diferencias técnicas  que deben ser consideradas y que serán presentadas a lo largo de las unidades de trabajo junto con  lós métodos necesarios para implementarlas.\n",
    "\n",
    "Antes de comenzar, proporcionaremos algunas definiciones formales y conceptos básicos.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b9fb515",
   "metadata": {},
   "source": [
    "## 2. Flujos de datos (*Data Streams*)\n",
    "\n",
    "En el núcleo del aprendizaje *online* se encuentra el término “flujo de datos” (*data stream*), que se define como la recopilación secuencial y continua de elementos individuales coherentes (observaciones). En el contexto de la información procesada por un algoritmo o sistema de aprendizaje automático, este flujo de datos normalmente consiste en datos (o metadatos) que pueden utilizarse para generar un conjunto de características medidas simultáneamente en el momento de su recepción. Estos datos suelen ser dependientes del tiempo o estar correlacionados temporalmente mediante una marca de tiempo. Por ejemplo, en una línea de producción podríamos considerar cada observación  como las medidas tomadas por los diferentes sensores desplegados por la fábrica para cada instante de tiempo.\n",
    "\n",
    "Una observación (o muestra) se define como el conjunto de características medidas en un instante específico. Estas muestras pueden tener una estructura de datos estable, es decir, en cada muestra están disponibles los mismos atributos para ser incluidos en la medición o modelo, o bien, la estructura de datos de la muestra puede ser “dinámica” o flexible, donde los atributos aparecen intermitentemente a lo largo del tiempo. La flexibilidad es una característica que no puede ser tratada por el paradigma tradicional de aprendizaje automático pero sí con el incremental.\n",
    "\n",
    "\n",
    "\n",
    "### 2.1. Flujos de datos reactivos y proactivos\n",
    "\n",
    "\n",
    "Los flujos de datos (*streams*) pueden clasificarse en dos tipos: reactivos y proactivos, dependiendo de su relación con el usuario.\n",
    "\n",
    "Los **flujos de datos reactivos** son aquellos en los que **el sistema \"recibe\" datos de un productor**. Un ejemplo típico es un sitio web que genera flujos de datos, como el servidor de datos de 'X' (*Twitter*) o también el sistema de producción de una factoría. En estos casos, la forma en que se produce el flujo de datos no está bajo el control del sistema de procesamiento; un sistema aprendizaje *online* simplemente actúa como receptor y no tiene influencia ni control más allá de recibir los datos y actuar en consecuencia. En este sentido, el sistema, simplemente,  \"reacciona\" a la entrada de datos.\n",
    "\n",
    "Los **flujos de datos proactivos** son aquellos en los que **el sistema controla cómo y cuándo se obtiene los datos desde el *stream***. Por ejemplo, se puede controlar el momento y la manera en que se leen los datos de un archivo. El sistema podría decidir a qué velocidad leer los datos, en qué orden, etc.\n",
    "\n",
    "\n",
    "\n",
    "## 3. Procesamiento *online*\n",
    "\n",
    "El concepto de “en línea” (*online*) se refiere al procesamiento de un flujo de datos (*stream*) observación por observación a medida que se van generando. Debido a ciertas confusiones con el término “*online education*”, suele emplearse el término *incremental learning* para evitar malos entendidos. En cualquier caso, el término se refiere al entrenamiento de un modelo mediante la incorporación de una muestra a la vez y la actualización de los pesos del modelo de manera continua.  \n",
    "De este modo, el aprendizaje incremental es significativamente diferente de los enfoques tradicionales de aprendizaje automático, que procesan datos en lotes (*batches*). \n",
    "Este cambio de metodología implica nuevos requisitos computacionales y técnicos. Por ejemplo, dado que en el procesamiento incremental las observaciones se gestionan de una en una, no se obtiene ningún beneficio de la vectorización y bibliotecas como NumPy y PyTorch solo generan un coste computacional adicional e innecesario.\n",
    "\n",
    "Es importante destacar que los modelos de aprendizaje *online*  son dinámicos y con estado. Este tipo de aprendizaje automático representa un nuevo paradigma en ML y, como cualquier otro método técnico, tiene ventajas y desventajas cuando se aplica a problemas del mundo real.\n",
    "\n",
    "\n",
    "##  4. Proceso de entrenamiento\n",
    "\n",
    "En la mayoría de las aplicaciones del mundo real los flujos de datos son reactivos pero, sin embargo, es habitual que para construir, entrenar y evaluar el rendimiento de un modelo de ML *online* , se genere un conjunto de datos que simule el comportamiento del flujo de datos (*data stream* proactivo). Como veremos, la librería River gestiona esto de manera elegante al convertir el conjunto de datos en un objeto [generador](https://wiki.python.org/moin/Generators) de Python. Una vez desarrollado el modelo, el flujo de datos en tiempo real puede reemplazar sin inconvenientes la versión de desarrollo. \n",
    "Es importante destacar que los modelos de ML *online* no requieren ser entrenados de esta forma, ya que es posible desplegarlos directamente y aprender el tiempo real, no obstante, es habitual desplegarlos con un mínimo de entrenamiento para evitar grandes errores al comienzo.\n",
    "\n",
    "Hay una diferencia fundamental en la forma en la que el aprendizaje automático tradicional y el aprendizaje incremental entrenan los modelos. En el aprendizaje tradicional el conjunto de datos histórico se divide en entrenamiento y evaluación. El conjunto de evaluación se reserva y no se emplea hasta que el modelo está entrenado pero, sin embargo, en el aprendizaje *online*, se emplean todos los datos para las dos etapas (entrenamiento y evaluación).\n",
    "Así, cuando llega una nueva observación, la aproximación *online* la usa para evaluar el modelo y luego ajusta los pesos del modelo (entrenamiento) en consecuencia. Este proceso se repite continuamente para todo los datos del *stream*, por lo que el orden temporal de las observaciones es crucial en el desarrollo del modelo. En contraste, en el aprendizaje tradicional, los datos suelen dividirse y mezclarse aleatoriamente para reducir correlaciones estadísticas. \n",
    "\n",
    "\n",
    "El orden temporal garantiza que el modelo se ajuste a la realidad de los datos en cada instante de tiempo y es clave para descubrir la estructura causal subyacente de la información y realizar los ajustes necesarios para realizar predicciones más precisas en el futuro.\n",
    "\n",
    "\n",
    "\n",
    "## 5. Concept Drift\n",
    "\n",
    "En el contexto de los flujos de datos, la razón principal por la que el aprendizaje automático tradicional falla (o al menos no es tan adecuado y requiere procesos complicados de reentrenamiento) es el fenómeno conocido como *concept drift*. Este término se refiere a la situación en la que los datos cambian o evolucionan con el tiempo, haciendo que los modelos entrenados con datos pasados queden obsoletos. \n",
    "\n",
    "Si bien, como veremos, el *concept drift* también es un reto para las aproximaciones incrementales, la ventaja de estas es que los ajustes en los modelos se realizan de manera continua intentando adaptarse a dichos cambios. \n",
    "No obstante, este sigue siendo un campo de investigación activo, que exploraremos con mayor profundidad durante el curso\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f324f102",
   "metadata": {},
   "source": [
    "## 6. Librerías para trabajar con Aprendizaje Automático incremental\n",
    "\n",
    "Dado que el ML *online* es un paradigma relativamente nuevo, todavía existen pocas implementaciones y pocas de estas están suficientemente maduras. \n",
    "A continuación, se presenta un resumen de algunas de las principales librerías que podéis encontrar:\n",
    "\n",
    "* **[Apache SAMOA](https://incubator.apache.org/projects/samoa.html)**, un proyecto para realizar análisis y minería de datos en flujos de datos. Cuenta con módulos específicos para aprendizaje automático. No obstante, el proyecto no se ha actualizado desde 2020 y sigue en la fase de incubación de la Fundación Apache (AP). ~~Además, se rumorea que la AP tiene planes de abandonar su desarrollo.~~ Finalmente, el proyecto SAMOA fue retirado.\n",
    "\n",
    "* **[MOA](https://moa.cms.waikato.ac.nz/)**, escrito en Java,  desarrollado por los mismos autores del proyecto WEKA y con una estrecha relación con dicho proyecto. Incluye una colección de algoritmos de aprendizaje automático (clasificación, regresión, clustering, detección de valores atípicos, detección de concept drift y sistemas de recomendación) y herramientas para la evaluación. Su uso está principalmente limitado a la interfaz que proporciona o a la implementación de extensiones enfocadas a la integración con el resto del ecosistema.\n",
    "\n",
    "* **[Vowpal wabbit](https://vowpalwabbit.org/)**, una librería de Python soportada por Microsoft. Ofrece herramientas enfocadas al ML *online* pero con un énfasis particular en problemas de aprendizaje por refuerzo. Una desventaja significativa es que requiere un formato de entrada de datos específico (poco intuitivo), lo que limita en gran medida su usabilidad.\n",
    "\n",
    "* **[River](https://riverml.xyz/)**, una librería de Python enfocada en al aprendizaje incremental, que ha adoptado un enfoque más general (y *pythonic*) en comparación con *Vowpal Wabbit*. En esta librería, el número de modelos es similar a los de scikit-learn, y además ofrece herramientas para interactuar con el ecosistema de scikit-learn a través de *wrappers*. También permite desarrollar soluciones de aprendizaje por refuerzo. Su principal ventaja es que resulta muy simple e intuitivo para los nuevos desarrolladores, sobre todo si tienen experiencia en el *pipeline* de scikit-learn. Además permite trabajar con los tipos de datos más comunes como, por ejemplo, [Pandas](https://pandas.pydata.org/) DataFrames.\n",
    "\n",
    "Durante las prácticas enfocadas al aprendizaje incremental, emplearemos River como librería para el desarrollo de soluciones.\n",
    "Mediante el uso de River, describiremos diferentes casos de uso y abordaremos muchos de los problemas comunes en el aprendizaje *online* o incremental.\n",
    "\n",
    "El resto de este Notebook explorará algunos ejemplos comunes empleando River.\n",
    "\n",
    "- El repositorio de código de River está disponible en el siguiente enlace: [River Repository](https://github.com/online-ml/river/tree/main/river)\n",
    "- La referencia de la API de River está disponible en el siguiente enlace: [River API](https://riverml.xyz/latest/api/overview/)\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "205a5777",
   "metadata": {},
   "source": [
    "## 7. Aprendizaje online supervisado: Clasificación binaria\n",
    "\n",
    "Este es quizás el ejemplo más elemental del aprendizaje automático, y proporciona un buen punto de partida para discutir el aprendizaje *online*. En este caso, el modelo tiene una única salida que describe a cuál de las dos clases pertenece la muestra.\n",
    "\n",
    "Pasos: \n",
    "\n",
    "1. **Instalar la librería** (si no está instalada, se llama al comando pip).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es necesario al menos una versión de  Python >3.8\n",
    "#Si tenéis el entorno virtual correctamente creado, esto no se ejecutará\n",
    "try:\n",
    "    import river\n",
    "except ImportError as err:\n",
    "    !pip install river\n",
    "\n",
    "    \n",
    "# Este librería genera un print mejorado\n",
    "# https://rich.readthedocs.io/en/stable/introduction.html\n",
    "#Si tenéis el entorno virtual correctamente creado, esto no se ejecutará\n",
    "try:\n",
    "    from rich import print\n",
    "except ImportError as err:\n",
    "    !pip install rich\n",
    "    from rich import print"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4288d5f7",
   "metadata": {},
   "source": [
    "2. **Importar el conjunto de datos**: para este ejemplo, hemos seleccionado un [conjunto de datos](https://riverml.xyz/latest/api/datasets/CreditCard/) que pertenece a los datasets de ejemplo de River, por su facilidad para cargarlo y procesarlo. Los datos representan operaciones con tarjetas de crédito y el objetivo es detectar fraudes bancarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from river import datasets #Datasets de River\n",
    "\n",
    "\n",
    "dataset = datasets.CreditCard()\n",
    "print(f\"El objeto contiene información sobre el datasets como, por ejemplo, el número de ejemplos y las características.\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observemos el primer ejemplo\n",
    "#Creamos un iterador para recorrer el dataset y obtenemos la primera observación\n",
    "#Cada observación está compuesta de sus características y su etiqueta asociada\n",
    "sample, target = next(iter(dataset)) \n",
    "print(\"Características:\")\n",
    "print(sample)\n",
    "print(\"Etiqueta:\")\n",
    "print(target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5e8d48a",
   "metadata": {},
   "source": [
    "Trabajar con clases desbalanceadas es una situación bastante común en el aprendizaje *online* (ej. detección de fraude o clasificación de spam).\n",
    "Como observamos en la descripción, el conjunto de datos CreditCard está claramente desbalanceado. Nosotros también podríamos calcular fácilmente el porcentaje de representación de los datos dentro de cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad47bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections #librería de Python\n",
    "\n",
    "#Genera un diccionario con las etiquetas y el número de observaciones que las contiene\n",
    "counts = collections.Counter(target for _, target in dataset)\n",
    "\n",
    "for label, count in counts.items():\n",
    "    print(f'{label}: {count} ({count / sum(counts.values()):.2%})')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3dd4bf02",
   "metadata": {},
   "source": [
    "En este ejemplo, nos centraremos en cómo procesar los datos empleando el paradigma incremental y no abordaremos el problema del desbalanceo pero, no obstante, existen diferentes aproximaciones para gestionar este tipo de problemas y mejorar el rendimiento de los modelos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31abb124",
   "metadata": {},
   "source": [
    "3. **Desarrollar un modelo para clasificación binaria**: Emplearemos un modelo básico ([logisticRegression](https://riverml.xyz/latest/api/linear-model/LogisticRegression/)) a modo de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import linear_model\n",
    "\n",
    "model = linear_model.LogisticRegression()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "036c1fe5",
   "metadata": {},
   "source": [
    "Sin entrenar adecuadamente el modelo, si procesamos una observación obtendremos como resultado que las probabilidades para cada clase son exactamente las mismas. La función `predict_proba_one` nos permite analizar dichas probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0fb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict_proba_one(sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66530209",
   "metadata": {},
   "source": [
    "Para cada clase, tenemos un clasificador aleatorio sin ningún conocimiento. Aquí es donde el método difiere del aprendizaje automático tradicional. La misma muestra que se usó para probar, también se usará para ajustar el modelo. Debéis tener en cuenta que las métricas de rendimiento deben calcularse antes de ajustar el modelo para que sean justas.\n",
    "\n",
    "4. **Entrenar el modelo con la observación actual**: el modelo se entrenará con los datos de la observación actual y su salida real, que deberemos de obtener de algún modo. Sin los datos reales, no podríamos ajustar el modelo. En una planta industrial es habitual predecir variables cuyos valores reales pueden ser medidos posteriormente en laboratorio o por sensórica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn_one(sample, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "015c33ac",
   "metadata": {},
   "source": [
    "Si probamos nuevamente la misma observación, veremos que las probabilidades han cambiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153346d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#En este ejemplo estamos reutilizando una observación empleada para ajustar los pesos para evaluar el modelo\n",
    "#Esto no es ni correcto ni justo y se realiza solo con fines académicos. \n",
    "#La secuencia adecuada para cada muestra sería: predicción - evaluación - entrenamiento.\n",
    "\n",
    "print(model.predict_proba_one(sample))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d70980bd",
   "metadata": {},
   "source": [
    "Para obtener la etiqueta de salida sin las probabilidades asociadas, se puede emplear la función: <code>predict_one()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82663a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict_one(sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a1ceef8",
   "metadata": {},
   "source": [
    "Veamos ahora un proceso completo en el que integramos en un bucle la predicción, la evaluación y el ajuste de los modelos. \n",
    "En este caso, usamos para evaluar el modelo la métrica estándar que consiste en el área bajo la curva [ROC](https://riverml.xyz/latest/api/metrics/ROCAUC/). No obstante, podríamos haber seleccionado cualquier otra métrica de las disponibles en River\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import metrics\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "metric = metrics.ROCAUC()\n",
    "\n",
    "for sample, target in dataset:\n",
    "    prediction = model.predict_proba_one(sample)\n",
    "    metric.update(target, prediction)\n",
    "    model.learn_one(sample, target)\n",
    "   \n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5910867",
   "metadata": {},
   "source": [
    "Una aproximación común y sencilla para mejorar el rendimiento del modelo es escalar los datos. River proporciona múltiples operaciones de preprocesamiento, incluyendo métodos para el escalado como, por ejemplo, la estandarización a través de [preprocessing.StandardScaler](https://riverml.xyz/latest/api/preprocessing/StandardScaler/). \n",
    "\n",
    "River proporciona una interfaz y sintaxis similar a `scikit-learn`, lo que simplificará su uso para desarrolladores que tengan conocimientos previos en dicha librería. En el siguiente ejemplo vemos como en River se pueden emplear e integrar *pipelines* de forma similar a `scikit-learn`.\n",
    "\n",
    "\n",
    "En este ejemplo, no escribiremos un bucle explícito para desarrollar el proceso de *entrenamiento-evaluación-actualización* porque la función <code> evaluate.progressive_val_score</code> lo realizará automáticamente por nosotros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import evaluate, compose, preprocessing\n",
    "\n",
    "#Ahora el \"modelo\" se compone de un paso de preprocesado + el propio modelo\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "metric = metrics.ROCAUC()\n",
    "evaluate.progressive_val_score(dataset, model, metric)\n",
    "\n",
    "#progressive_val_score es equivalente a:\n",
    "#for sample, target in dataset:\n",
    "#    prediction = model.predict_proba_one(sample)\n",
    "#    metric.update(target, prediction)\n",
    "#    model.learn_one(sample, target)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b26c3662",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "La métrica seleccionada para evaluar un modelo que trabaja con clases desbalanceadas es crítica. Puedes intentar evaluar el modelo usando la métrica de Precisión ([Accuracy](https://riverml.xyz/latest/api/metrics/Accuracy/)) (está incluida en la API de River). Verás que obtienes métricas impresionantes sin escalar los datos. Un modelo que siempre prediga la clase \"no fraude\" obtendrá una muy alta precisión, ya que es la clase mayoritaria. **Crea un *pipeline* empleando la métrica de precisión (*accuracy*)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb7cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea un pipeline empleando la métrica de precisión (accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60ced8b7",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "\n",
    "El coeficiente Kappa es una métrica muy útil para evaluar modelos con clases desbalanceadas. Este coeficiente mide la concordancia entre la etiqueta deseada y la etiqueta proporcionada por la salida del modelo, excluyendo la probabilidad de concordancia por azar. Esta métrica se considera generalmente más robusta que la precisión y su valor suele ser más bajo. El coeficiente [Kappa de Cohen](https://riverml.xyz/latest/api/metrics/CohenKappa/) también está disponible en River.\n",
    "\n",
    "\n",
    "\n",
    "**Evalúa el modelo usando la métrica *Kappa*. Comprueba cómo la métrica varía empleando la estandarización**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478377a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea un pipeline empleando la métrica Kappa\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d4777bb",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "¿Qué os parece si probamos con otro modelo? Repite el *pipeline* empleando otro modelo diferente. Por ejemplo, podéis emplear el [Perceptron](https://riverml.xyz/latest/api/linear-model/Perceptron/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb46f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea otro pipeline empleando otro modelo de aprendizaje automático\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efcae40f",
   "metadata": {},
   "source": [
    "## 7. Aprendizaje online supervisado: Clasificación multiclase\n",
    "\n",
    "El uso del aprendizaje *online* para realizar clasificación multiclase es el siguiente paso en complejidad que podemos considerar.\n",
    "Los pasos son similares a los empleados en la clasificación binaria, con la diferencia de que es necesario modificar las funciones de pérdida para tener en cuenta las múltiples etiquetas salidas. En el siguiente ejemplo, utilizamos otro [conjunto de datos](https://riverml.xyz/latest/api/datasets/ImageSegments/) de River que representa un conjunto de imágenes con 7 posibles clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from river import datasets\n",
    "\n",
    "dataset = datasets.ImageSegments()\n",
    "print(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6376c72e",
   "metadata": {},
   "source": [
    "Al igual que en la clasificación binaria, el conjunto de datos consiste en una serie de observaciones etiquetadas en formato de tupla (inputs, output). Una diferencia respecto al problema previo con el clasificador binario es la elección del clasificador multiclase. En este caso, empleamos un nuevo método de clasificación algo más complejo llamado [árbol de Hoeffding] (https://riverml.xyz/latest/api/tree/HoeffdingTreeClassifier/). Este clasificador pertenece al módulo \"tree\" de River. \n",
    "\n",
    "En el ejemplo podemos comprobar que, antes de entrenar, si imprimos las probabilidades de cada clase para una observación específica (`predict_proba_one`) obtendremos un diccionario vacío.  La razón es que el modelo aún no ha visto ninguna observación, por lo que no tiene información sobre las \"posibles\" clases. Si se tratara de un clasificador binario, emitiría una probabilidad del 50% para Verdadero y Falso porque las clases serían implícitas. Sin embargo, en este caso, como estamos realizando una clasificación multiclase,  la salida es nula. En consecuencia, el método `predict_one` inicialmente devolverá `None` porque el modelo aún no ha visto ningún ejemplo etiquetado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107832ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import tree\n",
    "\n",
    "data_stream = iter(dataset)\n",
    "sample, target = next(data_stream)\n",
    "\n",
    "model = tree.HoeffdingTreeClassifier()#modelo \"vacío\", sin entrenar\n",
    "print(\"Probabilidades del modelo sin entrenar:\", model.predict_proba_one(sample))\n",
    "\n",
    "print(\"Predicción de la clase del modelo sin entrenar:\", model.predict_one(sample))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb45f2c4",
   "metadata": {},
   "source": [
    "A medida que el modelo analice observaciones con sus respectivas etiquetas (clases), irá  añadiendo dichas clases a las probabilidades del propio modelo. Por ejemplo, una vez procesada la primera observación con su clase correspondiente, el modelo asociará un 100% de probabilidad de que la muestra pertenezca a dicha clase, ya que en ese punto no hay otras opciones posibles (solo se ha analizado una muestra). A medida que más muestras se analicen, más clases se añadirán al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6931677",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample, target)\n",
    "model.learn_one(sample, target)\n",
    "print(\"Probabilidades del modelo entrenado con 1 sola observación:\" , model.predict_proba_one(sample))\n",
    "print(\"Predicción de la clase del modelo entrenado con 1 sola observación: \", model.predict_one(sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1aa28b04",
   "metadata": {},
   "source": [
    "Si analizamos una segunda observación, veremos que las probabilidades cambian (estamos añadiendo una nueva etiqueta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e91e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, target = next(data_stream) # Siguiente observación en el stream\n",
    "print(sample, target)\n",
    "model.learn_one(sample, target)\n",
    "print(\"Probabilidades del modelo entrenado con 2 observaciones:\", model.predict_proba_one(sample))\n",
    "print(\"Predicción de la clase del modelo entrenado con 2 observaciones: \",model.predict_one(sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6a3517c",
   "metadata": {},
   "source": [
    "Este es uno de los puntos clave de los sistemas de clasificación incremental: **los modelos pueden gestionar la aparición de nuevas clases en el flujo de datos**.\n",
    "\n",
    "Típicamente, las observaciones se usan una vez para hacer una predicción y, cuando se realiza la predicción, la \"verdad de tierra\" (*ground-truth*) surgirá en algún momento posterior y se podrá emplear para evaluar el modelo y también para ajustarlo (entrenarlo). Este esquema se llama usualmente **validación progresiva**.\n",
    "\n",
    "Imaginaros en una fábrica suficientemente sensorizada en la que estamos prediciendo un resultado de calidad en la producción de un producto concreto. Nuestro objetivo es adelantarnos y predecir con suficientemente tiempo para poder actuar sobre la configuración pero llegará un momento en que los sensores desplegados realmente puedan \"leer\" la \"verdad de tierra\" y con ello ajustar el modelo.\n",
    "\n",
    "Probemos ahora con todas las observaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd262130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import metrics\n",
    "\n",
    "model = tree.HoeffdingTreeClassifier()\n",
    "\n",
    "metric = metrics.ClassificationReport()\n",
    "\n",
    "for sample, target in dataset:\n",
    "    prediction = model.predict_one(sample)\n",
    "    if prediction is not None:# la primera iteración la predicción será None y no puede emplearse para actualizar\n",
    "        metric.update(target, prediction)\n",
    "    model.learn_one(sample, target)\n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48b1f532",
   "metadata": {},
   "source": [
    "[ClassificationReport](https://riverml.xyz/latest/api/metrics/ClassificationReport/)  recupera el *accuracy*, el *recall* y el *F1-Score* para cada clase que el modelo ha visto. Además, la columna *Support* indica el número de instancias identificadas en el flujo.  Este ejemplo muestra un *pipeline* tan frecuente que River ha encapsulado todo el proceso en una sola función: `progresive_val_score`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14dae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import evaluate\n",
    "\n",
    "model = tree.HoeffdingTreeClassifier()\n",
    "metric = metrics.ClassificationReport()\n",
    "\n",
    "print(evaluate.progressive_val_score(dataset, model, metric))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15c9264c",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "**Emplea un modelo basado en los k vecinos más próximos para la clasificación multiclase**\n",
    "\n",
    "River proporciona modelos basados en los 'k' vecinos más próximos para la clasificación multiclase. Revisa los modelos disponibles y prueba el apropiado. Configura el proceso de evaluación para imprimir las métricas cada 1.000 observaciones.\n",
    "\n",
    "Este es un proceso que consume tiempo y recursos debido al tipo de modelo basado. Puedes detenerlo una vez que revises los primeros resultados de las métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6af401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emplea un modelo basado en los k vecinos más próximos para la clasificación multiclase\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfdd8ee2",
   "metadata": {},
   "source": [
    "## 7. Aprendizaje online supervisado: Regresión\n",
    "\n",
    "\n",
    "Por último,  veremos un ejemplo de regresión aplicado al aprendizaje incremental. Para este tipo de problemas, el modelo debe predecir una salida numérica dada una observación particular que representa la evolución de una serie temporal.\n",
    "\n",
    "Una observación de regresión consiste en varias características y una etiqueta, que generalmente se codifica como un número continuo (aunque también puede ser discreto). Un dataset útil, incluido en la biblioteca River, es el [dataset](https://riverml.xyz/latest/api/datasets/TrumpApproval/) de la tasa de aprobación de Trump.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff884e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "\n",
    "dataset = datasets.TrumpApproval()\n",
    "print(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de8d757d",
   "metadata": {},
   "source": [
    "Como se ve arriba, cada observación tiene 6 características que se utilizan para hacer una predicción en el rango $[0, 1]$. Para este problema, utilizaremos un modelo de regresión. En particular, usaremos un [KNN](https://riverml.xyz/0.14.0/api/neighbors/KNNRegressor/)  adaptado que está incluido en River.\n",
    "\n",
    "**Nota:** Ten en cuenta que los modelos de regresión no tienen el método `predict_proba_one()`, ya que no calculan probabilidades de clase.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import neighbors\n",
    "\n",
    "data_stream = iter(dataset)\n",
    "sample, target = next(data_stream)\n",
    "\n",
    "model = neighbors.KNNRegressor()\n",
    "print(\"Predicción del modelo sin entrenar:\", model.predict_one(sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a3c6d2",
   "metadata": {},
   "source": [
    "Como se puede ver, el modelo aún no ha sido entrenado y, por lo tanto, la salida predeterminada es $0.0$. Ahora, vamos a entrenar el modelo y repetir la predicción para ver cómo varía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526d8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn_one(sample, target)\n",
    "print(\"Predicción del modelo  entrenado con una sola observación:\", model.predict_one(sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f355c53",
   "metadata": {},
   "source": [
    "Desarrollaremos ahora el proceso de una forma más completa empleando la **validación progresiva**, tal y cómo se hizo en los casos anteriores, aplicando la secuencia de operaciones: predicción, evaluación y entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import metrics\n",
    "\n",
    "model = neighbors.KNNRegressor()\n",
    "\n",
    "metric = metrics.MAE()\n",
    "\n",
    "for sample, target in dataset:\n",
    "    prediction = model.predict_one(sample)\n",
    "    metric.update(target, prediction)\n",
    "    model.learn_one(sample, target)\n",
    "\n",
    "print(metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "339df89d",
   "metadata": {},
   "source": [
    "Lo mismo en notación compacta (recomendada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import evaluate\n",
    "\n",
    "model = neighbors.KNNRegressor()\n",
    "metric = metrics.MAE()\n",
    "\n",
    "evaluate.progressive_val_score(dataset, model, metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfd21f7f",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "Es importante destacar que los modelos que dependen de métricas de distancia son altamente sensibles a las variaciones en las escalas de las características. **Establece un *pipeline* de preprocesamiento que incluya la operación de estandarización y reevalúa el modelo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bebaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desarrolla un pipeline con estandarización y el modelo KNN\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
